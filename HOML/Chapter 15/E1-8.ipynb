{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
    "    - Sequence-to-sequence:\n",
    "        - Predict time series\n",
    "        - Translation\n",
    "        - Text to speech\n",
    "    - Sequence-to-vector:\n",
    "        - Sentiment analysis\n",
    "    - Vector-to-sequence:\n",
    "        - Image captioning\n",
    "        - Locate pedestrians in a picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?\n",
    "    - Input: 3D: \\[Batch_size, time steps, inputs per step\\]\n",
    "    - Output: 3D: \\[Batch_size, time steps, # of neurons\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should have `return_sequences=True`? What about a sequence-to-vector RNN?\n",
    "    - Deep S-T-S:\n",
    "        - All layers must have that argument\n",
    "    - Deep S-T-V:\n",
    "        - All layers must have that argument, except the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?\n",
    "    - Sequence to Sequence model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the main difficulties when training RNNs? How can you handle them?\n",
    "    - Fighting the Unstable Gradients Problem\n",
    "        - Good params initialization\n",
    "        - Faster optimizers\n",
    "        - Dropout\n",
    "        - Layer Normalization\n",
    "    - Tackling the Short-Term Memory Problem\n",
    "        - Use cells with long-term memory:\n",
    "            - LSTM cells (w | w/o Peephole connections)\n",
    "            - GRU cells\n",
    "        - Use 1D Conv layers\n",
    "        - WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Can you sketch the LSTM cellâ€™s architecture?\n",
    "    - LSTM contains of 2 state:\n",
    "        - Long-term state\n",
    "        - Short-term state\n",
    "    - Each timestep, inputs and previous short-term state are passed into LSTM cells, it pass to 3 gates:\n",
    "        - Forget gate (use logistic -> 0 and 1 -> Element wise product): Control which memory to keep in the long-term\n",
    "        - Input gate (Tanh gates, as usual): Extract the core stuff then save to long-term\n",
    "        - Output gate (use logistic -> 0 and 1 -> Element wise product): Decide which part of the long-term should be output at this time step.\n",
    "    - The new short-term state == output of the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Why would you want to use 1D convolutional layers in an RNN?\n",
    "    - RNN layer is sequential (since it has to wait for the previous outputs) -> **impossible to parallelize**\n",
    "    - 1D conv layer:\n",
    "        - Doesn't hold state between timestep -> No memory\n",
    "        - Leads to support parallelize \n",
    "        - Suffer less from unstable gradients (since it's not recurrent)\n",
    "        - Good for preprocess the inputs -> helps RNN layers detect long-term patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Which neural network architecture could you use to classify videos?\n",
    "    - Pass every frame to the same CNN, result sequence X\n",
    "    - Pass sequence X to S-T-V RNN, result vector Y\n",
    "    - Run Y through softmax layers, giving class probabilities\n",
    "    - Loss function: Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
