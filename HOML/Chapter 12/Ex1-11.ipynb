{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "    - Tensorflow is a library for numerical compputation and fine-tuned for Machine Learning.\n",
    "    - Its main features:\n",
    "        - ~ Numpy with GPU support\n",
    "        - Distributed computing\n",
    "        - Optimize computation for speed/ memory usage by extracing computation graph from Py function then optimize and run it\n",
    "        - Multiplatform for training (since computation graphs can be exported to portable format)\n",
    "        - Has autodiff, provide multiples tools for training\n",
    "    - Others:\n",
    "        - Pytorch\n",
    "        - FastAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "    - Functions between the two might be different.\n",
    "    - Numpy arrays are mutable, while Tensorflow's tensors are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = tf.range(10)\n",
    "b = tf.constant(np.arange(10))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, the results are different:\n",
    "    - `a` is created directly by tf, not being converted from numpy array to tensor as `b`\n",
    "    - As the result, by default, numpy use 64-bit precision, which is overkill for ML/ DL and increase the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "    - Sparse tensors: array with mostly zero\n",
    "    - Tensor arrays: list of tensors of same shape/type (fixed size by default)\n",
    "    - Ragged tensors: Static list of tensors of same shape/type\n",
    "    - String tensors: Tensor of type tf.string, represent byte string\n",
    "    - Sets: set\n",
    "    - Queues: multiple type of queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
    "    - **Using `keras.losses.Loss`**: When your function requires some parameters (e.g: threshold), and you want to save that information along with the model when calling the `save_model`, so that when we re-load (`load_model`), we still keep that threshold by subclassing this and implement the `get_config()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
    "    - Metrics using **simple function**: Keras can automatically calls it for each batch and keep track of the mean during each epoch\n",
    "    - Metrics using `keras.metrics.Metric`: \n",
    "        - Just as function, if metrics want to support some hyperparameters and save/load\n",
    "        - If computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch\n",
    "        - Some metrics can't be averaged over batches, so we need to implement a streaming metrics and do it ourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. When should you create a custom layer versus a custom model?\n",
    "    - Custom layer if we serve it as internel components for a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What are some use cases that require writing your own custom training loop?\n",
    "    - When we need to use multiple optimizers (e.g `Wide & Deeper paper` using two)\n",
    "    - When we want the model to train exactly as we told it to do, or more flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
    "    - Custom Keras components should be convertible to TF functions (by following TF function rules)\n",
    "    - We can wrap Python code with `tf.py_function()` (for function), or set `dynamic=True` (layers, models), set `run_eagerly=True` (for `model.compile()`) but it will reduce performance and limit model's portability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
    "    - We should minimize the use of third-party functions (since these function will only run duing tracing and not be a part of the graph)\n",
    "    - Can call other Python functions/ TF Functions but they should follow the same rules\n",
    "    - TensorFlow Variable must be created at the very first call or else will raise exception.\n",
    "        - It is more preferable to create variable outside of tf function\n",
    "        - Using `.assign()` not `=`\n",
    "    - Source code should be available to TF or else the graph generation process will fail/ limited functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "    - Create: \n",
    "        - By passing `dynamic=True` to the constructor\n",
    "        - Pass `run_eagerly=True` when `model.compile()`\n",
    "    - When: \n",
    "        - For debugging (it won't ocmpile any custom component to TF function), can use Python debugger\n",
    "        - Include abitrary Python code in the model\n",
    "        - Calls to external library\n",
    "    - Why not:\n",
    "        - Slow down training/ inference\n",
    "        - Can't export computational graph -> limit portability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
